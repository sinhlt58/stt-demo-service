{"version":3,"sources":["constants/constants.tsx","services/socketio.tsx","pages/home.style.ts","pages/home.tsx","App.tsx","reportWebVitals.ts","index.tsx"],"names":["WS_STATE","socketio","useStyles","makeStyles","theme","createStyles","root","overflow","height","micContainer","mic","display","cursor","fontSize","HomePage","useState","isMicOn","setIsMicOn","undefined","recorder","setRecorder","localAudioStream","setLocalAudioStream","setBlobURL","sttText","setSttText","classes","io","handleOnEventSocketIO","message","useEffect","on","cleanUpMic","console","log","stopRecording","blob","getBlob","reader","FileReader","readAsDataURL","onloadend","a","base64String","result","split","url","URL","createObjectURL","getAudioTracks","forEach","track","stop","Box","width","flexDirection","className","justifyContent","alignItems","onClick","event","navigator","mediaDevices","getUserMedia","video","audio","then","stream","RecordRTC","type","mimeType","recorderType","StereoAudioRecorder","disableLogs","timeSlice","ondataavailable","emit","desiredSampRate","bitrate","bitsPerSecond","numberOfAudioChannels","startRecording","App","Container","maxWidth","reportWebVitals","onPerfEntry","Function","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"iIAKYA,E,sJAAAA,O,2BAAAA,I,eAAAA,I,qBAAAA,I,oBAAAA,M,KAOL,I,iBCTHC,EAAgB,K,sBCDPC,EAAYC,aAAW,SAACC,GAAD,OAChCC,YAAa,CACTC,KAAM,CAEFC,SAAU,SACVC,OAAQ,SAEZC,aAAc,GAGdC,IAAK,CACDC,QAAS,QACTC,OAAQ,UACRC,SAAU,S,OCqJPC,EArJE,WACb,MAA4BC,oBAAS,GAArC,mBAAKC,EAAL,KAAcC,EAAd,KACA,EAA8BF,wBAAcG,GAA5C,mBAAKC,EAAL,KAAeC,EAAf,KACA,EAA8CL,wBAAcG,GAA5D,mBAAKG,EAAL,KAAuBC,EAAvB,KACA,EAA4BP,wBAAcG,GAA1C,mBAAcK,GAAd,WACA,EAA4BR,mBAAiB,IAA7C,mBAAKS,EAAL,KAAcC,EAAd,KAEMC,EAAUxB,IAGVD,GFnBDA,IACDA,EAAW0B,IDLZ,4BCOI1B,GE6CD2B,EAAwB,SAACC,GAC3BJ,EAAWI,IAGfC,qBAAU,WAEN7B,EAAS8B,GAAG,MAAOH,KACpB,IAEHE,qBAAU,WACDd,GACDgB,MAEL,CAAChB,IAEJ,IAsCMgB,EAAa,WACfC,QAAQC,IAAI,aACRf,GACAA,EAASgB,eAAc,WACnBF,QAAQC,IAAI,UACZ,IAAIE,EAAOjB,EAASkB,UAChBC,EAAS,IAAIC,WACjBD,EAAOE,cAAcJ,GACrBE,EAAOG,UAAP,sBAAmB,4BAAAC,EAAA,uDACXC,EAAoBL,EAAOM,UAE3BD,EAAeA,EAAaE,MAAM,KAAK,IAH5B,2CAanB,IAAIC,EAAMC,IAAIC,gBAAgBZ,GAC9BH,QAAQC,IAAIY,GACZvB,EAAWuB,MAGfzB,IACAY,QAAQC,IAAI,6BAEZb,EAAiB4B,iBAAiBC,SAAQ,SAASC,GAAYA,EAAMC,UACrE/B,OAAmBH,IAI3B,OACI,eAAC,WAAD,WACI,4CAAeM,KACf,eAAC6B,EAAA,EAAD,CAAKC,MAAM,OACN9C,OAAO,QACPG,QAAQ,OACR4C,cAAc,SACdC,UAAW9B,EAAQpB,KAJxB,UAKI,cAAC+C,EAAA,EAAD,CAAKC,MAAM,OAAO9C,OAAO,OACzB,eAAC6C,EAAA,EAAD,CAAKC,MAAM,OAAO9C,OAAO,MACpBG,QAAQ,OACR8C,eAAe,SACfC,WAAW,SACXF,UAAW9B,EAAQjB,aAJxB,WAMMO,GAAW,cAAC,IAAD,CAASwC,UAAW9B,EAAQhB,IAAKiD,QAvFxC,SAACC,GACnBnC,EAAW,IACXoC,UAAUC,aAAaC,aAAa,CAChCC,OAAO,EACPC,OAAO,IACRC,KAHH,uCAGQ,WAAOC,GAAP,eAAAzB,EAAA,sDACJpB,EAAoB6C,IAChBhD,EAAW,IAAIiD,IAAUD,EAAQ,CACjCE,KAAM,QACNC,SAAU,YACVC,aAAcC,sBACdC,aAAa,EACbC,UAAW,IACXC,gBAAgB,WAAD,4BAAE,WAAOvC,GAAP,SAAAM,EAAA,sDAITzC,GACAA,EAAS2E,KAAK,MAAOxC,GALZ,2CAAF,mDAAC,GAQhByC,gBAAiB,KACjBC,QAAS,MACTC,cAAe,MACfC,sBAAuB,KAElBC,iBACT7D,EAAYD,GAtBR,2CAHR,uDA2BAF,GAAW,MA2DED,GAAW,cAAC,IAAD,CAAUwC,UAAW9B,EAAQhB,IAAKiD,QAxDxC,SAACC,GACnB5B,IACAf,GAAW,gB,SC3FJiE,MARf,WACI,OACI,cAACC,EAAA,EAAD,CAAWC,SAAS,KAApB,SACI,cAAC,EAAD,OCOGC,EAZS,SAACC,GACnBA,GAAeA,aAAuBC,UACxC,8BAAqBrB,MAAK,YAAkD,IAA/CsB,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOF,GACPG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAQN,OCHdO,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1BZ,K","file":"static/js/main.480fc0f0.chunk.js","sourcesContent":["export const { REACT_APP_VOICE_ASSISTANT_API_URL = '' } = process.env;\nexport const { REACT_APP_SPEECH_TO_TEXT_ENDPOINT = '' } = process.env\nexport const { REACT_APP_STT_SOCKETIO_ENDPOINT = '' } = process.env\n\n\nexport enum WS_STATE {\n    CONNECTING = 0,\n    OPEN = 1,\n    CLOSING = 2,\n    CLOSED = 3,\n}\n\nexport const END_OF_FILE = 'EOF';\n","import io from \"socket.io-client\";\nimport { REACT_APP_STT_SOCKETIO_ENDPOINT } from '../constants/constants';\n\nlet socketio: any = null;\n\nexport function getSocketIO(){\n    if (!socketio){\n        socketio = io(REACT_APP_STT_SOCKETIO_ENDPOINT);\n    }\n    return socketio;\n}\n","import { makeStyles, Theme, createStyles } from \"@material-ui/core/styles\";\n\nexport const useStyles = makeStyles((theme: Theme) =>\n    createStyles({\n        root: {\n            // backgroundColor: '#cfe8fc',\n            overflow: 'scroll',\n            height: \"100vh\"\n        },\n        micContainer: {\n            // textAlign: \"center\"\n        },\n        mic: {\n            display: 'block',\n            cursor: 'pointer',\n            fontSize: 80,\n        }\n    })\n);","import { Box } from \"@material-ui/core\";\nimport MicIcon from '@material-ui/icons/Mic';\nimport StopIcon from '@material-ui/icons/Stop';\nimport { Fragment, useEffect, useState } from \"react\";\nimport RecordRTC, {StereoAudioRecorder} from 'recordrtc'\nimport { END_OF_FILE, WS_STATE } from \"../constants/constants\";\nimport { voiceAssistantService } from \"../services/voice.assistant.service\";\nimport { getSocket } from \"../services/websocket\";\nimport { getSocketIO } from \"../services/socketio\";\n\nimport { useStyles } from \"./home.style\";\n\n\nlet ackCount = 0;\n\nconst HomePage = () => {\n    let [isMicOn, setIsMicOn] = useState(false);\n    let [recorder, setRecorder] = useState<any>(undefined);\n    let [localAudioStream, setLocalAudioStream] = useState<any>(undefined);\n    let [blobURL, setBlobURL] = useState<any>(undefined);\n    let [sttText, setSttText] = useState<string>(\"\");\n\n    const classes = useStyles();\n\n    // const socket = getSocket();\n    const socketio: any = getSocketIO();\n\n    const handleOnMessageSocket = (event: any) => {\n        if (event.data) {\n            const result = JSON.parse(event.data);\n            switch (result.type) {\n                case 'TEXT':\n                    const text = result.result;\n                    setSttText(text);\n                    break;\n                case 'CLOSE_SEND':\n                    // cleanUpMic();\n                    setIsMicOn(false);\n                    console.log('CLOSE_SEND');\n                    break;\n                case 'ACK':\n                    ackCount += 1;\n                    if (ackCount > 3000) {\n                        ackCount = 0;\n                        setIsMicOn(false);\n                        getSocket().send(new Blob([END_OF_FILE]));\n                    }\n                    break;\n                default:\n                    break;\n            }\n        }\n    }\n\n    const handleOnEventSocketIO = (message: any) => {\n        setSttText(message);\n    }\n\n    useEffect(() => {\n        // socket.onmessage = handleOnMessageSocket;\n        socketio.on(\"stt\", handleOnEventSocketIO);\n    }, [])\n\n    useEffect(() => {\n        if (!isMicOn){\n            cleanUpMic();\n        }\n    }, [isMicOn])\n\n    const handleStarMic = (event: any) => {\n        setSttText(\"\");\n        navigator.mediaDevices.getUserMedia({\n            video: false,\n            audio: true\n        }).then(async (stream) => {\n            setLocalAudioStream(stream);\n            let recorder = new RecordRTC(stream, {\n                type: \"audio\",\n                mimeType: \"audio/wav\",\n                recorderType: StereoAudioRecorder,\n                disableLogs: true,\n                timeSlice: 100,\n                ondataavailable: async (blob: Blob) => {\n                    // if (socket.readyState === WS_STATE.OPEN) {\n                    //     socket.send(blob);\n                    // }\n                    if (socketio){\n                        socketio.emit(\"stt\", blob);\n                    }\n                },\n                desiredSampRate: 16000,\n                bitrate: 128000,\n                bitsPerSecond: 128000,\n                numberOfAudioChannels: 1,\n            });\n            recorder.startRecording();\n            setRecorder(recorder);\n        });\n        setIsMicOn(true);\n    }\n\n    const handleStopMic = (event: any) => {\n        cleanUpMic();\n        setIsMicOn(false);\n        // socket.send(new Blob([END_OF_FILE]));\n    }\n\n    const cleanUpMic = () => {\n        console.log(\"clean mic\")\n        if (recorder){\n            recorder.stopRecording(() => {\n                console.log(\"stoped\")\n                let blob = recorder.getBlob();\n                let reader = new FileReader();\n                reader.readAsDataURL(blob);\n                reader.onloadend = async () => {\n                    let base64String: any = reader.result;\n                    if (base64String){\n                        base64String = base64String.split(\",\")[1];\n                        // try {\n                        //     let res = await voiceAssistantService.stt(base64String);\n                        //     console.log(res.data);\n                        //     setSttText(res.data.text);\n                        // } catch (e){\n                        //     console.log(\"ERROR: \" + e)\n                        // }\n                    }\n                }\n                let url = URL.createObjectURL(blob);\n                console.log(url);\n                setBlobURL(url);\n            })\n        }\n        if (localAudioStream){\n            console.log(\"remove local audio stream\")\n            // turn off the mic stream\n            localAudioStream.getAudioTracks().forEach(function(track: any){track.stop();});\n            localAudioStream = undefined;\n        }\n    }\n\n    return (\n        <Fragment>\n            <h2>STT text: {sttText}</h2>\n            <Box width=\"100%\"\n                 height=\"100vh\"\n                 display=\"flex\"\n                 flexDirection=\"column\"\n                 className={classes.root}>\n                <Box width=\"100%\" height=\"2%\"></Box>\n                <Box width=\"100%\" height=\"20%\"\n                     display=\"flex\"\n                     justifyContent=\"center\"\n                     alignItems=\"center\"\n                     className={classes.micContainer}\n                >\n                    {!isMicOn && <MicIcon className={classes.mic} onClick={handleStarMic}></MicIcon>}\n                    {isMicOn && <StopIcon className={classes.mic} onClick={handleStopMic}></StopIcon>}\n                </Box>\n            </Box>\n        </Fragment>\n    )\n}\n\nexport default HomePage;","import './App.css';\nimport HomePage from './pages/home';\nimport { Container } from '@material-ui/core';\n\nfunction App() {\n    return (\n        <Container maxWidth=\"sm\">\n            <HomePage></HomePage>\n        </Container>\n    );\n}\n\nexport default App;\n","import { ReportHandler } from 'web-vitals';\n\nconst reportWebVitals = (onPerfEntry?: ReportHandler) => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}